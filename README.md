# Instacart Data API - SIT223 Task 7.3HD

A complete end-to-end CI/CD pipeline for processing and serving Instacart dataset through a REST API.

## ğŸ—ï¸ Architecture Overview

```
ğŸ“¦ Project Structure
â”œâ”€â”€ ğŸ“‚ app/                    # FastAPI application
â”‚   â”œâ”€â”€ main.py               # API endpoints
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ ğŸ“‚ etl/                   # ETL pipeline
â”‚   â”œâ”€â”€ clean.py              # Data processing
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ ğŸ“‚ tests/                 # Test suite
â”‚   â”œâ”€â”€ test_etl.py          # ETL tests
â”‚   â”œâ”€â”€ test_api.py          # API tests
â”‚   â”œâ”€â”€ test_integration.py  # Integration tests
â”‚   â””â”€â”€ conftest.py          # Test configuration
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ raw/                 # Raw CSV files (not in repo)
â”‚   â””â”€â”€ clean/               # Processed data
â”œâ”€â”€ ğŸ“‚ reports/              # Generated reports
â”œâ”€â”€ ğŸ“‚ config/               # Configuration files
â”œâ”€â”€ ğŸ³ Dockerfile           # Container configuration
â”œâ”€â”€ ğŸ³ docker-compose.staging.yml
â”œâ”€â”€ ğŸ”§ Jenkinsfile          # CI/CD pipeline
â”œâ”€â”€ ğŸ“‹ requirements.txt     # Python dependencies
â””â”€â”€ ğŸ“š README.md            # This file
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- Docker & Docker Compose
- Git

### 1. Local Development Setup

```bash
# Clone repository
git clone <your-repo-url>
cd csv-clean-api

# Move your Instacart CSV files to data/raw/
mkdir -p data/raw
# Copy: aisles.csv, departments.csv, orders.csv, products.csv, order_products__*.csv

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run ETL pipeline
python -m etl.clean --raw-data-path data/raw --clean-data-path data/clean

# Start API server
uvicorn app.main:app --reload --port 8000
```

### 2. Docker Deployment

```bash
# Build and run with Docker Compose
docker-compose -f docker-compose.staging.yml up --build

# API will be available at http://localhost:8000
```

### 3. Running Tests

```bash
# Run all tests with coverage
pytest

# Run specific test categories
pytest -m unit        # Unit tests only
pytest -m integration # Integration tests only
pytest -m "not slow"  # Skip slow tests

# Generate coverage report
pytest --cov=app --cov=etl --cov-report=html
```

## ğŸ“¡ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | API information |
| `/health` | GET | Health check with data availability |
| `/summary` | GET | Dataset summary statistics |
| `/filter` | GET | Filter and query dataset |
| `/validations/last` | GET | Last ETL validation results |
| `/docs` | GET | Interactive API documentation |

### Example API Usage

```bash
# Health check
curl http://localhost:8000/health

# Get dataset summary
curl http://localhost:8000/summary

# Filter products by department
curl "http://localhost:8000/filter?department=produce&limit=10"

# Get validation results
curl http://localhost:8000/validations/last
```

## ğŸ”§ Jenkins Pipeline

The CI/CD pipeline includes **7 comprehensive stages**:

### Stage Overview
1. **Build** - Setup environment & run ETL
2. **Test** - Unit tests with coverage reporting
3. **Code Quality** - Ruff linting & MyPy type checking
4. **Security** - Bandit, pip-audit, Trivy scans
5. **Deploy** - Docker staging deployment
6. **Release** - Tag and prepare artifacts
7. **Monitoring** - Health checks and API validation

### Pipeline Features
- âœ… JUnit XML test reports
- ğŸ“Š Coverage reporting with 70% threshold
- ğŸ” Security vulnerability scanning
- ğŸ³ Docker image building and scanning
- ğŸ“ˆ Quality gate enforcement
- ğŸš¨ Build status management (UNSTABLE for warnings)

### Artifacts Generated
- `reports/junit.xml` - Test results
- `reports/coverage.xml` - Coverage report
- `reports/bandit.json` - Security scan results
- `reports/trivy.json` - Container vulnerability scan
- `data/clean/` - Processed dataset

## ğŸ› ï¸ Development Workflow

### Code Quality Standards
```bash
# Lint code
ruff check .

# Type checking
mypy app/ etl/

# Security scan
bandit -r app/ etl/

# Format code (optional)
black app/ etl/ tests/
```

### ETL Pipeline Details

The ETL pipeline (`etl/clean.py`) performs:
1. **Data Loading** - Reads CSV files from `data/raw/`
2. **Data Merging** - Joins products, aisles, departments
3. **Data Validation** - Schema validation and quality checks
4. **Data Enhancement** - Computed fields and analytics
5. **Output Generation** - Clean CSV + validation JSON

### API Design

FastAPI application features:
- **Pydantic models** for request/response validation
- **Async endpoints** for better performance
- **Error handling** with proper HTTP status codes
- **CORS support** for frontend integration
- **Health checks** for container orchestration

## ğŸ”’ Security & Quality

### Security Measures
- ğŸ›¡ï¸ **Bandit** - Python security linting
- ğŸ” **pip-audit** - Dependency vulnerability scanning
- ğŸ³ **Trivy** - Container image security scanning
- ğŸ‘¤ **Non-root Docker user** for container security

### Quality Assurance
- ğŸ“ **Ruff** - Fast Python linter
- ğŸ” **MyPy** - Static type checking
- ğŸ§ª **Pytest** - Comprehensive test suite
- ğŸ“Š **Coverage** - 70% minimum threshold

## ğŸ³ Docker Configuration

### Multi-stage Build
- Base: Python 3.11 slim
- Security: Non-root user
- Health checks: Built-in endpoint monitoring
- Optimization: Layer caching for faster builds

### Staging Environment
- Port: 8000
- Health checks: 30s intervals
- Volume mounts: Data persistence
- Network: Isolated bridge network

## ğŸ“Š Monitoring & Observability

### Health Monitoring
- Application health endpoint
- Container health checks
- API endpoint validation
- Data availability verification

### Metrics Collection
- Test coverage metrics
- Code quality scores
- Security vulnerability counts
- API response times

## ğŸš¨ Troubleshooting

### Common Issues

**ETL Pipeline Fails:**
```bash
# Check data files exist
ls -la data/raw/

# Check Python environment
python --version
pip list

# Run with verbose logging
python -m etl.clean --raw-data-path data/raw --clean-data-path data/clean
```

**API Won't Start:**
```bash
# Check port availability
netstat -an | grep 8000

# Check data files
ls -la data/clean/

# Run with debug mode
uvicorn app.main:app --reload --log-level debug
```

**Docker Issues:**
```bash
# Check container logs
docker logs instacart-api-staging

# Check container health
docker ps
docker inspect instacart-api-staging
```

### Jenkins Pipeline Issues

**Pipeline Fails at ETL Stage:**
- Ensure raw data files are in `data/raw/`
- Check Python environment setup
- Verify file permissions

**Tests Fail:**
- Check test data availability
- Verify virtual environment activation
- Review test logs in Jenkins console

**Security Scans Mark Build Unstable:**
- Review Bandit findings in `reports/bandit.json`
- Check pip-audit results for dependency vulnerabilities
- Examine Trivy scan for container vulnerabilities

## ğŸ“š Additional Resources

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Docker Best Practices](https://docs.docker.com/develop/dev-best-practices/)
- [Jenkins Pipeline Documentation](https://www.jenkins.io/doc/book/pipeline/)
- [Instacart Dataset](https://www.kaggle.com/c/instacart-market-basket-analysis)

## ğŸ‘¥ Contributing

1. Fork the repository
2. Create feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push to branch: `git push origin feature/amazing-feature`
5. Open a Pull Request

## ğŸ“„ License

This project is created for educational purposes (SIT223 Task 7.3HD).

---

**Built with â¤ï¸ for SIT223 High Distinction Task**